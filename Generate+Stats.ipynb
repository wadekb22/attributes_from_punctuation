{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LEFT TO DO:\n",
    " \n",
    "'''\n",
    "- Integrate this code into the main data_collection.ipynb, specifically, get the appropriate parts under the generate_stats function. \n",
    "- Work on outputting the stats correctly.\n",
    "- F6 as in Darmon's work?\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from string import punctuation\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function which splits text input into individual sentances. Used in generation of f4.\n",
    "\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "alphabets= \"([A-Za-z])\"\n",
    "digits = \"([0-9])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text) \n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input, our array of the ten most recent comments from a single Redditor.\n",
    "comment_list = [\"35, I have a pretty good job but I don't love it. I'm still trying to figure out what I want to be when I grow up. Situation could be a lot worse but I'm at a point where I want to do something I enjoy.\", \"My family (live with my real mom and step dad) act like me being outed by older sister never happened. And on top of all of this I'm struggling trying to study for my math ged which I failed six times with being 1 point shy from passing. If I fail it again, its another two months of waiting to retake it.\", \"I'm really not sure how i'm supposed to feel anymore knowing that most of my life I was just wasting my time.\", \"I'm an IT apprentice and was about a month away from finishing my level 4 course. My training provider has just closed down due to a fraud investigation so now im in a position of trying to find a provider for my specific course so I can finish. And there's no guarantee my years work can be transferred so I may not even be able to get my certificate without another years of work.\", \"29 and I don't like being a mum\", \"I was going to complain about being a 24yo male who's single and doesn't want to be but some of these responses make mine a drop in the bucket compared to the waters some of you face. Best of luck to all of you.\", \"Split up with my long term so of 5 years and decided to go for a complete career change. Going to pack in this life and go travel for a bit. Experience the world and figure out what it is I want.\", \"I'm 30, diagnosed last year with ADHS, failed university this year, just needed to write my thesis, no intimacy with my girlfriend of 2 years anymore. Yeah Life!\", \"32, alcoholic, narcissistic, sociopath, broke, in debt, and i feel eventually my finances will magically fix themselves. I’m also a cocky piece of shit who doesn’t take advice or think there’s anything wrong with me. I truthfully think I’m ok. I need help. So much.\", \"My dad has lung cancer and is refusing treatment, which is fine. He's a 68 year old man who loves to drink and smoke and has accepted the hand he was dealt. He doesn't have to go through treatment if he doesn't want too.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell deals with reformatting of the comment-array input.\n",
    "\n",
    "# Concatinates all the comments into one sample of the Redditor's writing (string object).\n",
    "writing_sample = ' '.join(comment_list)\n",
    "\n",
    "# Now, we need to check for instances of elipses and assign them to a new symbol--less confusion with periods, easier analysis.\n",
    "# The tilde will represent an elipse from here on out.\n",
    "writing_sample = writing_sample.replace('...', '~')\n",
    "\n",
    "\n",
    "# We will loop over every character in the string and extract the punctuation, appending each mark to a list.\n",
    "# We will keep this punctuation sequence in both list and string form for further analysis.\n",
    "marks = ['.',',',':',';','?','!','-','(',')','\"',\"'\",'~']\n",
    "marks_str = ''.join(map(str, marks))\n",
    "\n",
    "punct_list = []\n",
    "\n",
    "for character in writing_sample:\n",
    "    if character in marks:\n",
    "        punct_list.append(character)\n",
    "      \n",
    "punct_str = ''.join(punct_list)\n",
    "\n",
    "# Now, we want to get our input in the following format..[2, '!', 3, '.'].\n",
    "split_by_punc = (x.split() for x in re.split('[' + punctuation + ']', writing_sample))\n",
    "wrds_btwn = list(map(len, split_by_punc))\n",
    "woven = list(chain.from_iterable(zip(wrds_btwn, punct_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of f1, relative frequency of each punctuation mark of interest.\n",
    "num_period = punct_str.count('.')\n",
    "num_comma = punct_str.count(',')\n",
    "num_colon = punct_str.count(':')\n",
    "num_semicol = punct_str.count(';')\n",
    "num_question = punct_str.count('?')\n",
    "num_exclaim = punct_str.count('!')\n",
    "num_dash = punct_str.count('-')\n",
    "num_left_paren = punct_str.count('(')\n",
    "num_right_paren = punct_str.count(')')\n",
    "num_sing_quote = punct_str.count(\"'\")\n",
    "num_doub_quote = punct_str.count('\"')\n",
    "num_elipse = punct_str.count('~')\n",
    "\n",
    "mark_counts = [num_period, num_comma, num_colon, num_semicol, num_question, num_exclaim, num_dash, num_left_paren, num_right_paren, num_sing_quote, num_doub_quote, num_elipse] \n",
    "f1 = [x / len(punct_list) for x in mark_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation of f2 and f3, conditional/joint probability of observing two punctuation marks in succession.\n",
    "f2 = {}\n",
    "f3 = {}\n",
    "successive_pairs = []\n",
    "combos = list(itertools.product(marks_str, marks_str))\n",
    "\n",
    "for i in combos:\n",
    "    successive_pairs.append(''.join(i))\n",
    "\n",
    "for pair in successive_pairs:\n",
    "    numerator = punct_str.count(pair)\n",
    "    denominator = punct_str.count(pair[0])\n",
    "    \n",
    "    if numerator != 0:\n",
    "        f2['Conditional Prob' + ' ' + pair + ' '] = (numerator/denominator)\n",
    "        f3['Joint Prob' + ' ' + pair + ' '] = (numerator/len(punct_list))\n",
    "    else:\n",
    "        f2['Conditional Prob' + ' ' + pair + ' '] = 0\n",
    "        f3['Joint Prob' + ' ' + pair + ' '] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generation of f4, redditor's average sentence length in words.\n",
    "sent_lens = []\n",
    "regex = \"\\w+('\\w+)?(?<!('s))\"\n",
    "sentences = split_into_sentences(writing_sample)\n",
    "\n",
    "for sentence in sentences:\n",
    "    sent_lens.append(len(re.findall(regex, sentence)))\n",
    "    \n",
    "f4 = mean(sent_lens)\n",
    "\n",
    "# f4 as a probability distribution of sentence length--as it is in Darmon's work.\n",
    "# Cap sentence length at 199 words.\n",
    "F4 = [0]*200\n",
    "\n",
    "for i in sent_lens:\n",
    "    F4[i] += 1\n",
    "    \n",
    "F4 = [x / len(sent_lens) for x in F4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generation of f5, redditor's average number of words between successive punctuation marks.\n",
    "f5 = mean(wrds_btwn)\n",
    "\n",
    "# f5 as a probability distribution of number of words between successive marks--as it is in Darmon's work.\n",
    "# Cap number of in-between words at 39.\n",
    "F5 = [0]*40\n",
    "\n",
    "for i in wrds_btwn:\n",
    "    F5[i] += 1\n",
    "    \n",
    "F5 = [x / len(wrds_btwn) for x in F5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generation of f6, ratio of punctuation to words.\n",
    "total_punc = len(punct_list)\n",
    "total_words = len(re.findall(regex, writing_sample))\n",
    "\n",
    "f6 = total_punc/total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
