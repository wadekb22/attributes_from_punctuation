{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LEFT TO DO:\n",
    " \n",
    "'''\n",
    "- Integrate this code into the main data_collection.ipynb, specifically, get the appropriate parts under the generate_stats function. \n",
    "- Work on outputting the stats correctly.\n",
    "- F6 as in Darmon's work?\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "from string import punctuation\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function which splits text input into individual sentances. Used in generation of f4.\n",
    "\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "alphabets= \"([A-Za-z])\"\n",
    "digits = \"([0-9])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text) \n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input, our array of the ten most recent comments from a single Redditor.\n",
    "comment_list = [\"35, I have a pretty good job but I don't love it. I'm still trying to figure out what I want to be when I grow up. Situation could be a lot worse but I'm at a point where I want to do something I enjoy.\", \"My family (live with my real mom and step dad) act like me being outed by older sister never happened. And on top of all of this I'm struggling trying to study for my math ged which I failed six times with being 1 point shy from passing. If I fail it again, its another two months of waiting to retake it.\", \"I'm really not sure how i'm supposed to feel anymore knowing that most of my life I was just wasting my time.\", \"I'm an IT apprentice and was about a month away from finishing my level 4 course. My training provider has just closed down due to a fraud investigation so now im in a position of trying to find a provider for my specific course so I can finish. And there's no guarantee my years work can be transferred so I may not even be able to get my certificate without another years of work.\", \"29 and I don't like being a mum\", \"I was going to complain about being a 24yo male who's single and doesn't want to be but some of these responses make mine a drop in the bucket compared to the waters some of you face. Best of luck to all of you.\", \"Split up with my long term so of 5 years and decided to go for a complete career change. Going to pack in this life and go travel for a bit. Experience the world and figure out what it is I want.\", \"I'm 30, diagnosed last year with ADHS, failed university this year, just needed to write my thesis, no intimacy with my girlfriend of 2 years anymore. Yeah Life!\", \"32, alcoholic, narcissistic, sociopath, broke, in debt, and i feel eventually my finances will magically fix themselves. I’m also a cocky piece of shit who doesn’t take advice or think there’s anything wrong with me. I truthfully think I’m ok. I need help. So much.\", \"My dad has lung cancer and is refusing treatment, which is fine. He's a 68 year old man who loves to drink and smoke and has accepted the hand he was dealt. He doesn't have to go through treatment if he doesn't want too.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create read-only reddit instance\n",
    "import praw\n",
    "\n",
    "# This should be moved to a private praw.ini file at some point\n",
    "reddit = praw.Reddit(\n",
    " client_id=\"kuf-S39ElN0SpA\",\n",
    " client_secret=\"XVSM3GfyGRbhbdeXh-s3AtNqnP2FCg\",\n",
    " user_agent=\"pc:attributes.from.punctuation:v1.0.0 (by u/dscc440bot)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_list = []  # contains strings of comment text\n",
    "redditor = \"Ex_gamer\"\n",
    "start_time = 1596240000\n",
    "end_time = 1604188800\n",
    "redditor = reddit.redditor(redditor)\n",
    "    \n",
    "try:\n",
    "    for comment in redditor.comments.new(limit=None):\n",
    "        if comment.created_utc > start_time and comment.created_utc < end_time:  # Check if comment is within time range\n",
    "            comment_list.append(comment.body)\n",
    "except:\n",
    "    print(\"Account not valid (probably suspended).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HAAANS GET ZE FLAMMENWEHFER', 'BBFFDCAAAKE']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAAANS GET ZE FLAMMENWEHFER BBFFDCAAAKE\n"
     ]
    }
   ],
   "source": [
    "# This cell deals with reformatting of the comment-array input.\n",
    "\n",
    "# Concatinates all the comments into one sample of the Redditor's writing (string object).\n",
    "writing_sample = ' '.join(comment_list)\n",
    "\n",
    "# Remove new line\n",
    "writing_sample = writing_sample.replace('\\n', \" \")\n",
    "\n",
    "# Removing all non-ASCII letters\n",
    "writing_sample = writing_sample.encode(\"ascii\", \"ignore\").decode()\n",
    "\n",
    "# Remove URLs from comments\n",
    "writing_sample = re.sub(r'\\(https?:\\/\\/.*?\\)', '', writing_sample)\n",
    "\n",
    "print(writing_sample)\n",
    "\n",
    "# Now, we need to check for instances of elipses and assign them to a new symbol--less confusion with periods, easier analysis.\n",
    "# The tilde will represent an elipse from here on out.\n",
    "writing_sample = writing_sample.replace('...', '~')\n",
    "\n",
    "\n",
    "# We will loop over every character in the string and extract the punctuation, appending each mark to a list.\n",
    "# We will keep this punctuation sequence in both list and string form for further analysis.\n",
    "marks = ['.',',',':',';','?','!','-','(',')','\"',\"'\",'~']\n",
    "marks_str = ''.join(map(str, marks))\n",
    "\n",
    "punct_list = []\n",
    "\n",
    "for character in writing_sample:\n",
    "    if character in marks:\n",
    "        punct_list.append(character)\n",
    "      \n",
    "punct_str = ''.join(punct_list)\n",
    "\n",
    "# Now, we want to get our input in the following format..[2, '!', 3, '.'].\n",
    "split_by_punc = (x.split() for x in re.split('[' + punctuation + ']', writing_sample))\n",
    "wrds_btwn = list(map(len, split_by_punc))\n",
    "woven = list(chain.from_iterable(zip(wrds_btwn, punct_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-f35b617d0e70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmark_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnum_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_comma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_colon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_semicol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_question\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_exclaim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_dash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_left_paren\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_right_paren\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_sing_quote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_doub_quote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_elipse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mF1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpunct_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmark_counts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-f35b617d0e70>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmark_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnum_period\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_comma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_colon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_semicol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_question\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_exclaim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_dash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_left_paren\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_right_paren\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_sing_quote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_doub_quote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_elipse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mF1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpunct_list\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmark_counts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "# Generation of F1, relative frequency of each punctuation mark of interest.\n",
    "num_period = punct_str.count('.')\n",
    "num_comma = punct_str.count(',')\n",
    "num_colon = punct_str.count(':')\n",
    "num_semicol = punct_str.count(';')\n",
    "num_question = punct_str.count('?')\n",
    "num_exclaim = punct_str.count('!')\n",
    "num_dash = punct_str.count('-')\n",
    "num_left_paren = punct_str.count('(')\n",
    "num_right_paren = punct_str.count(')')\n",
    "num_sing_quote = punct_str.count(\"'\")\n",
    "num_doub_quote = punct_str.count('\"')\n",
    "num_elipse = punct_str.count('~')\n",
    "\n",
    "mark_counts = [num_period, num_comma, num_colon, num_semicol, num_question, num_exclaim, num_dash, num_left_paren, num_right_paren, num_sing_quote, num_doub_quote, num_elipse] \n",
    "F1 = [x / len(punct_list) for x in mark_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '!', '!', '!', '!', '!']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generation of F2 and F3, conditional/joint probability of observing two punctuation marks in succession.\n",
    "F2_dict = {}\n",
    "F3_dict = {}\n",
    "successive_pairs = []\n",
    "combos = list(itertools.product(marks_str, marks_str))\n",
    "\n",
    "for i in combos:\n",
    "    successive_pairs.append(''.join(i))\n",
    "\n",
    "for pair in successive_pairs:\n",
    "    numerator = punct_str.count(pair)\n",
    "    denominator = punct_str.count(pair[0])\n",
    "    \n",
    "    if numerator != 0:\n",
    "        F2_dict['Conditional Prob' + ' ' + pair + ' '] = (numerator/denominator)\n",
    "        F3_dict['Joint Prob' + ' ' + pair + ' '] = (numerator/len(punct_list))\n",
    "    else:\n",
    "        F2_dict['Conditional Prob' + ' ' + pair + ' '] = 0\n",
    "        F3_dict['Joint Prob' + ' ' + pair + ' '] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generation of f4, redditor's average sentence length in words.\n",
    "sent_lens = []\n",
    "regex = \"\\w+('\\w+)?(?<!('s))\"\n",
    "sentences = split_into_sentences(writing_sample)\n",
    "\n",
    "for sentence in sentences:\n",
    "    sent_lens.append(len(re.findall(regex, sentence)))\n",
    "    \n",
    "f4 = mean(sent_lens)\n",
    "\n",
    "# f4 as a probability distribution of sentence length--as it is in Darmon's work.\n",
    "# Cap sentence length at 199 words.\n",
    "F4 = [0]*200\n",
    "\n",
    "for i in sent_lens:\n",
    "    F4[i] += 1\n",
    "    \n",
    "F4 = [x / len(sent_lens) for x in F4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generation of f5, redditor's average number of words between successive punctuation marks.\n",
    "f5 = mean(wrds_btwn)\n",
    "\n",
    "# f5 as a probability distribution of number of words between successive marks--as it is in Darmon's work.\n",
    "# Cap number of in-between words at 39.\n",
    "F5 = [0]*40\n",
    "\n",
    "for i in wrds_btwn:\n",
    "    F5[i] += 1\n",
    "    \n",
    "F5 = [x / len(wrds_btwn) for x in F5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generation of f6, ratio of punctuation to words.\n",
    "total_punc = len(punct_list)\n",
    "total_words = len(re.findall(regex, writing_sample))\n",
    "\n",
    "f6 = total_punc/total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate a non-NDFrame object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-ab3ec045964d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#dataset = pd.DataFrame(master, index=[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/genevieverowe/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity)\u001b[0m\n\u001b[1;32m   4643\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4644\u001b[0m         return concat(to_concat, ignore_index=ignore_index,\n\u001b[0;32m-> 4645\u001b[0;31m                       verify_integrity=verify_integrity)\n\u001b[0m\u001b[1;32m   4646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4647\u001b[0m     def join(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/Users/genevieverowe/anaconda/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    204\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/genevieverowe/anaconda/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot concatenate a non-NDFrame object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate a non-NDFrame object"
     ]
    }
   ],
   "source": [
    "# Output to dataframe.\n",
    "# An uppercase F signals that the feature was mimicked directly from Darmon's work.\n",
    "F1_dict_keys = ['Period Freq', 'Comma Freq', 'Colon Freq', 'Semicol Freq', 'Question Freq', 'Exclaim Freq', 'Dash Freq', 'L. Paren Freq', 'R. Paren Freq', 'S. Quote Freq', 'D. Quote Freq', 'Elipse Freq']\n",
    "F1_dict = {F1_dict_keys[i]: F1[i] for i in range(len(F1_dict_keys))} \n",
    "\n",
    "F4_dict = {'Prob Sentence Len:' + ' ' + str(i): F4[i] for i in range(len(F4))}\n",
    "F5_dict = {'Prob' + ' ' + str(i) + ' ' + 'Words Between Punc': F5[i] for i in range(len(F5))}\n",
    "\n",
    "# Concatinate all the keys into a single list.\n",
    "master = {**F1_dict, **F2_dict, **F3_dict, **F4_dict, **F5_dict}\n",
    "#dataset = pd.DataFrame(master, index=[0])\n",
    "dataset = pd.DataFrame(columns = master.keys())\n",
    "dataset.append(master.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period Freq</th>\n",
       "      <th>Comma Freq</th>\n",
       "      <th>Colon Freq</th>\n",
       "      <th>Semicol Freq</th>\n",
       "      <th>Question Freq</th>\n",
       "      <th>Exclaim Freq</th>\n",
       "      <th>Dash Freq</th>\n",
       "      <th>L. Paren Freq</th>\n",
       "      <th>R. Paren Freq</th>\n",
       "      <th>S. Quote Freq</th>\n",
       "      <th>...</th>\n",
       "      <th>Prob 30 Words Between Punc</th>\n",
       "      <th>Prob 31 Words Between Punc</th>\n",
       "      <th>Prob 32 Words Between Punc</th>\n",
       "      <th>Prob 33 Words Between Punc</th>\n",
       "      <th>Prob 34 Words Between Punc</th>\n",
       "      <th>Prob 35 Words Between Punc</th>\n",
       "      <th>Prob 36 Words Between Punc</th>\n",
       "      <th>Prob 37 Words Between Punc</th>\n",
       "      <th>Prob 38 Words Between Punc</th>\n",
       "      <th>Prob 39 Words Between Punc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Period Freq, Comma Freq, Colon Freq, Semicol Freq, Question Freq, Exclaim Freq, Dash Freq, L. Paren Freq, R. Paren Freq, S. Quote Freq, D. Quote Freq, Elipse Freq, Conditional Prob .. , Conditional Prob ., , Conditional Prob .: , Conditional Prob .; , Conditional Prob .? , Conditional Prob .! , Conditional Prob .- , Conditional Prob .( , Conditional Prob .) , Conditional Prob .\" , Conditional Prob .' , Conditional Prob .~ , Conditional Prob ,. , Conditional Prob ,, , Conditional Prob ,: , Conditional Prob ,; , Conditional Prob ,? , Conditional Prob ,! , Conditional Prob ,- , Conditional Prob ,( , Conditional Prob ,) , Conditional Prob ,\" , Conditional Prob ,' , Conditional Prob ,~ , Conditional Prob :. , Conditional Prob :, , Conditional Prob :: , Conditional Prob :; , Conditional Prob :? , Conditional Prob :! , Conditional Prob :- , Conditional Prob :( , Conditional Prob :) , Conditional Prob :\" , Conditional Prob :' , Conditional Prob :~ , Conditional Prob ;. , Conditional Prob ;, , Conditional Prob ;: , Conditional Prob ;; , Conditional Prob ;? , Conditional Prob ;! , Conditional Prob ;- , Conditional Prob ;( , Conditional Prob ;) , Conditional Prob ;\" , Conditional Prob ;' , Conditional Prob ;~ , Conditional Prob ?. , Conditional Prob ?, , Conditional Prob ?: , Conditional Prob ?; , Conditional Prob ?? , Conditional Prob ?! , Conditional Prob ?- , Conditional Prob ?( , Conditional Prob ?) , Conditional Prob ?\" , Conditional Prob ?' , Conditional Prob ?~ , Conditional Prob !. , Conditional Prob !, , Conditional Prob !: , Conditional Prob !; , Conditional Prob !? , Conditional Prob !! , Conditional Prob !- , Conditional Prob !( , Conditional Prob !) , Conditional Prob !\" , Conditional Prob !' , Conditional Prob !~ , Conditional Prob -. , Conditional Prob -, , Conditional Prob -: , Conditional Prob -; , Conditional Prob -? , Conditional Prob -! , Conditional Prob -- , Conditional Prob -( , Conditional Prob -) , Conditional Prob -\" , Conditional Prob -' , Conditional Prob -~ , Conditional Prob (. , Conditional Prob (, , Conditional Prob (: , Conditional Prob (; , ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 540 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
